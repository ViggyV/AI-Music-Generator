{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN 3.0\n",
    "Through my research, I was able to decided to use a GAN to create music. I would first convert .wav files to pngs and use that throughout my GAN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The import statement above is used for some prints and special uses from tensorflow beta 2.0. Below of the required import statements to run and use the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import glob#finds pathnames\n",
    "import imageio#handles image input and output\n",
    "import matplotlib.pyplot as plt#data visulization\n",
    "import numpy as np#obivous array and math uses\n",
    "import os#helps uses files across different os\n",
    "import PIL#pictures\n",
    "import numpy\n",
    "import math\n",
    "from PIL import Image\n",
    "from scipy.io.wavfile import read, write\n",
    "from tensorflow.keras import layers#layers in the neural nets\n",
    "import time#to figure out timings\n",
    "from tqdm import tqdm\n",
    "\n",
    "from IPython import display#will show the resulting converted pngs\n",
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputting .wav files and Converting them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out\n",
      "vs1-2fug.wav\n",
      "work\n",
      "after png\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-46317ff57bf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# split all 16-bit integers in WAV file to 2x 8 bit integers;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# 1 16 bit int per pixel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0md_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>>\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0xff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0xff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0md_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>>\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0xff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0xff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mpng_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "os.chdir(\"/Users/viggy/Documents/GitHub/AI-Music-Generator/ViolinMIDI/bwv1001\")\n",
    "# read the WAV data\n",
    "wavs_in = []\n",
    "png_data = []\n",
    "song=0\n",
    "print(\"out\")\n",
    "\n",
    "for filename in glob.glob(\"*.wav\"):\n",
    "    print(filename)\n",
    "    print(\"work\")\n",
    "    wavs_in.append(read(filename))\n",
    "    wav_data = list(wavs_in[song][1])\n",
    "    #print(list(wavs_in[song]))\n",
    "    png_data = []\n",
    "    print(\"after png\")\n",
    "    for d in wav_data:\n",
    "        # split all 16-bit integers in WAV file to 2x 8 bit integers;\n",
    "        # 1 16 bit int per pixel\n",
    "        d_1 = (((d[0] >> 8) & 0xff), d[0] & 0xff, 0)\n",
    "        d_2 = (((d[1] >> 8) & 0xff), d[1] & 0xff, 0)\n",
    "        png_data.append(d_1)\n",
    "        png_data.append(d_2)\n",
    "    print(\"append\")\n",
    "    # ending indicator pixel uses the green channel\n",
    "    # (green channel set to 0 for all data pixels)\n",
    "    png_data += [(255, 255, 255)]\n",
    "    # find a roughly square size of output image\n",
    "    n = len(png_data)\n",
    "    x = math.floor(math.sqrt(n))\n",
    "    y = x + math.ceil((n - x ** 2) / x)\n",
    "\n",
    "    # output the PNG image\n",
    "    img = PIL.Image.new('RGB', (int(x), int(y)), color = 'white')\n",
    "    img.putdata(png_data)\n",
    "    img.save(filename.replace(\".wav\",\".png\"))\n",
    "    song+=1\n",
    "print(\"fin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(image_path, saved_location):\n",
    "    print(\"start cropping\")\n",
    "    images=[]\n",
    "    \n",
    "    image_obj = Image.open(image_path)\n",
    "    current_x=0\n",
    "    current_y=0\n",
    "    next_x=28\n",
    "    next_y=28\n",
    "    coords=[current_x,current_y,next_x,next_y]\n",
    "    count=30\n",
    "    i=0\n",
    "    pbar = tqdm(total=30)\n",
    "    while i<=30 and next_y < image_obj.size[1]:\n",
    "        while next_x < image_obj.size[0]:\n",
    "            cropped_image = image_obj.crop(coords)\n",
    "            #cropped_image.save(saved_location)\n",
    "            images.append(cropped_image)\n",
    "            coords=[current_x+28,current_y,next_x+28,next_y]\n",
    "            i+=1\n",
    "        current_x,current_y,next_x,next_y=0\n",
    "        coords=[current_x,current_y,next_x+28,next_y+28]\n",
    "    \n",
    "    \n",
    "    cropped_image.show()\n",
    "    print(\"Done Cropping\")\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_model():\n",
    "\n",
    "    model=tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256,use_bias=True,input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.ReLU())\n",
    "\n",
    "    model.add(layers.Reshape((7,7,256)))\n",
    "    assert model.output_shape==(None,7,7,256)\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128,(5,5),strides=(1,1),padding='same',use_bias=True))\n",
    "    assert model.output_shape==(None,7,7,128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.ReLU())\n",
    "    \n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(64,(5,5),strides=(2,2),padding='same',use_bias=True))\n",
    "    assert model.output_shape==(None,14,14,64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.ReLU())\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(1,(5,5),strides=(2,2),padding='same',use_bias=True,activation='sigmoid'))\n",
    "    assert model.output_shape==(None,28,28,1)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xb347eec18>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator=generator_model()\n",
    "\n",
    "noise=tf.random.normal([1, 100])\n",
    "generated_image=generator(noise,training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0],cmap='RdYlGn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_model():\n",
    "    model=tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64,(5,5),strides=(2,2),padding=\"same\",input_shape=[28,28,1]))\n",
    "    model.add(layers.ReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Conv2D(128,(5,5),strides=(2,2),padding='same'))\n",
    "    model.add(layers.ReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-0.05279009]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "discriminator=discriminator_model()\n",
    "decision=discriminator(generated_image)\n",
    "print(decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Losses and Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras helper function to compute cross entropy loss\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,discriminator_optimizer=discriminator_optimizer,generator=generator,discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# We will reuse this seed overtime (so it's easier)\n",
    "# to visualize progress in the animated GIF)\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "      generated_images = generator(noise, training=True)\n",
    "\n",
    "      real_output = discriminator(images, training=True)\n",
    "      fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "      gen_loss = generator_loss(fake_output)\n",
    "      disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "\n",
    "    for image_batch in dataset:\n",
    "      train_step(image_batch)\n",
    "\n",
    "    # Produce images for the GIF as we go\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator,\n",
    "                             epoch + 1,\n",
    "                             seed)\n",
    "\n",
    "    # Save the model every 15 epochs\n",
    "    if (epoch + 1) % 15 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "  # Generate after the final epoch\n",
    "  display.clear_output(wait=True)\n",
    "  generate_and_save_images(generator,epochs,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  # Notice `training` is set to False.\n",
    "  # This is so all layers run in inference mode (batchnorm).\n",
    "  predictions = model(test_input, training=False)\n",
    "\n",
    "  fig = plt.figure(figsize=(4,4))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "      plt.subplot(4, 4, i+1)\n",
    "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "      plt.axis('off')\n",
    "\n",
    "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "going to decode\n",
      "decode\n",
      "start cropping\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from scipy import ndimage, misc\n",
    "filepath=\"/Users/viggy/Documents/GitHub/AI-Music-Generator/ViolinMIDI/bwv1001/vs1-1ada.png\"\n",
    "data=plt.imread(filepath)\n",
    "data.shape\n",
    "#mage_resized = misc.imresize(image, (64, 64))\n",
    "#data = data.reshape(28, 28, 1).astype('float32')\n",
    "#data = (data - 127.5) / 127.5 # Normalize the images to [-1, 1]\n",
    "images = []\n",
    "print(\"going to decode\")\n",
    "#image1=tf.image.decode_png(Image.open(filepath))\n",
    "print(\"decode\")\n",
    "#image1=image1.reshape(uploaded.shape[0],28,28,1).astype('float32')\n",
    "#uploaded=(uploaded-127.5)/127.5\n",
    "images=crop(\"/Users/viggy/Documents/GitHub/AI-Music-Generator/ViolinMIDI/bwv1001/vs1-1ada.png\",\n",
    "           \"/Users/viggy/Documents/GitHub/AI-Music-Generator/ViolinMIDI/bwv1001/vs1-1ada\")\n",
    "print(\"reshaped\")\n",
    "#images.append(image_resized)\n",
    "train(images, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
