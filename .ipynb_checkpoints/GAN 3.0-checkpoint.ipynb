{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN 3.0\n",
    "Through my research, I was able to decided to use a GAN to create music. I would first convert .wav files to pngs and use that throughout my GAN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The import statement above is used for some prints and special uses from tensorflow beta 2.0. Below of the required import statements to run and use the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import glob#finds pathnames\n",
    "import imageio#handles image input and output\n",
    "import matplotlib.pyplot as plt#data visulization\n",
    "import numpy as np#obivous array and math uses\n",
    "import os#helps uses files across different os\n",
    "import PIL#pictures\n",
    "from PIL import Image\n",
    "from scipy.io.wavfile import read, write\n",
    "from tensorflow.keras import layers#layers in the neural nets\n",
    "import time#to figure out timings\n",
    "\n",
    "from IPython import display#will show the resulting converted pngs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputting .wav files and Converting them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import math\n",
    "\n",
    "\n",
    "# read the WAV data\n",
    "wav_in = read(\"/Users/viggy/\")\n",
    "wav_data = list(wav_in[1])\n",
    "\n",
    "png_data = []\n",
    "for d in wav_data:\n",
    "    # split all 16-bit integers in WAV file to 2x 8 bit integers;\n",
    "    # 1 16 bit int per pixel\n",
    "    d_1 = (((d[0] >> 8) & 0xff), d[0] & 0xff, 0)\n",
    "    d_2 = (((d[1] >> 8) & 0xff), d[1] & 0xff, 0)\n",
    "    png_data.append(d_1)\n",
    "    png_data.append(d_2)\n",
    "\n",
    "# ending indicator pixel uses the green channel\n",
    "# (green channel set to 0 for all data pixels)\n",
    "png_data += [(255, 255, 255)]\n",
    "\n",
    "# find a roughly square size of output image\n",
    "n = len(png_data)\n",
    "x = math.floor(math.sqrt(n))\n",
    "y = x + math.ceil((n - x ** 2) / x)\n",
    "\n",
    "# output the PNG image\n",
    "img = PIL.Image.new('RGB', (int(x), int(y)), color = 'white')\n",
    "img.putdata(png_data)\n",
    "img.save(\"out.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_model():\n",
    "\n",
    "    model=tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256,use_bias=True,input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.ReLU())\n",
    "\n",
    "    model.add(layers.Reshape((7,7,256)))\n",
    "    assert model.output_shape==(None,7,7,256)\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128,(5,5),strides=(1,1),padding='same',use_bias=True))\n",
    "    assert model.output_shape==(None,7,7,128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.ReLU())\n",
    "    \n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(64,(5,5),strides=(2,2),padding='same',use_bias=True))\n",
    "    assert model.output_shape==(None,14,14,64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.ReLU())\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(1,(5,5),strides=(2,2),padding='same',use_bias=True,activation='sigmoid'))\n",
    "    assert model.output_shape==(None,28,28,1)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xb3f8cfda0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator=generator_model()\n",
    "\n",
    "noise=tf.random.normal([1, 100])\n",
    "generated_image=generator(noise,training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0],cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_model():\n",
    "    model=tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64,(5,5),strides=(2,2),padding=\"same\",input_shape=[28,28,1]))\n",
    "    model.add(layers.ReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Conv2D(128,(5,5),strides=(2,2),padding='same'))\n",
    "    model.add(layers.ReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.10119933]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "discriminator=discriminator_model()\n",
    "decision=discriminator(generated_image)\n",
    "print(decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Losses and Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras helper function to compute cross entropy loss\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,discriminator_optimizer=discriminator_optimizer,generator=generator,discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# We will reuse this seed overtime (so it's easier)\n",
    "# to visualize progress in the animated GIF)\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "      generated_images = generator(noise, training=True)\n",
    "\n",
    "      real_output = discriminator(images, training=True)\n",
    "      fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "      gen_loss = generator_loss(fake_output)\n",
    "      disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "\n",
    "    for image_batch in dataset:\n",
    "      train_step(image_batch)\n",
    "\n",
    "    # Produce images for the GIF as we go\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator,\n",
    "                             epoch + 1,\n",
    "                             seed)\n",
    "\n",
    "    # Save the model every 15 epochs\n",
    "    if (epoch + 1) % 15 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "  # Generate after the final epoch\n",
    "  display.clear_output(wait=True)\n",
    "  generate_and_save_images(generator,epochs,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  # Notice `training` is set to False.\n",
    "  # This is so all layers run in inference mode (batchnorm).\n",
    "  predictions = model(test_input, training=False)\n",
    "\n",
    "  fig = plt.figure(figsize=(4,4))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "      plt.subplot(4, 4, i+1)\n",
    "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "      plt.axis('off')\n",
    "\n",
    "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train(, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
