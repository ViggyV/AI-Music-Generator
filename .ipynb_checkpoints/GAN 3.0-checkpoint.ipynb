{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN 3.0\n",
    "Through my research, I was able to decided to use a GAN to create music. I would first convert .wav files to pngs and use that throughout my GAN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The import statement above is used for some prints and special uses from tensorflow beta 2.0. Below of the required import statements to run and use the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import glob#finds pathnames\n",
    "import imageio#handles image input and output\n",
    "import matplotlib.pyplot as plt#data visulization\n",
    "import numpy as np#obivous array and math uses\n",
    "import os#helps uses files across different os\n",
    "import PIL#pictures\n",
    "import numpy\n",
    "import math\n",
    "from PIL import Image\n",
    "from scipy.io.wavfile import read, write\n",
    "from tensorflow.keras import layers#layers in the neural nets\n",
    "import time#to figure out timings\n",
    "from tqdm import tqdm\n",
    "import image_slicer\n",
    "from pathlib import Path\n",
    "from IPython import display#will show the resulting converted pngs\n",
    "BATCH_SIZE = 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputting .wav files and Converting them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out\n",
      "out.wav\n",
      "work\n"
     ]
    }
   ],
   "source": [
    "\n",
    "os.chdir(\"/Users/viggy/Documents/GitHub/AI-Music-Generator/ViolinMIDI/bwv1001\")\n",
    "# read the WAV data\n",
    "wavs_in = []\n",
    "png_data = []\n",
    "song=0\n",
    "print(\"out\")\n",
    "\n",
    "for filename in glob.glob(\"*.wav\"):\n",
    "    print(filename)\n",
    "    print(\"work\")\n",
    "    wavs_in.append(read(filename))\n",
    "    wav_data = list(wavs_in[song][1])\n",
    "    #print(list(wavs_in[song]))\n",
    "    png_data = []\n",
    "    print(\"after png\")\n",
    "    for d in wav_data:\n",
    "        # split all 16-bit integers in WAV file to 2x 8 bit integers;\n",
    "        # 1 16 bit int per pixel\n",
    "        d_1 = (((d[0] >> 8) & 0xff), d[0] & 0xff, 0)\n",
    "        d_2 = (((d[1] >> 8) & 0xff), d[1] & 0xff, 0)\n",
    "        png_data.append(d_1)\n",
    "        png_data.append(d_2)\n",
    "    print(\"append\")\n",
    "    # ending indicator pixel uses the green channel\n",
    "    # (green channel set to 0 for all data pixels)\n",
    "    png_data += [(255, 255, 255)]\n",
    "    # find a roughly square size of output image\n",
    "    n = len(png_data)\n",
    "    x = math.floor(math.sqrt(n))\n",
    "    y = x + math.ceil((n - x ** 2) / x)\n",
    "\n",
    "    # output the PNG image\n",
    "    img = PIL.Image.new('RGB', (int(x), int(y)), color = 'white')\n",
    "    img.putdata(png_data)\n",
    "    img.save(filename.replace(\".wav\",\".png\"))\n",
    "    song+=1\n",
    "print(\"fin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(img):\n",
    "    print(\"start cropping\")\n",
    "    images=[]\n",
    "    print(img)\n",
    "    #image_obj = Image.open(image_path)\n",
    "    #%pylab inline\n",
    "    #import matplotlib.pyplot as plt\n",
    "    #import matplotlib.image as mpimg\n",
    "    #img=mpimg.imread('your_image.png')\n",
    "    #imgplot = plt.imshow(img)\n",
    "    #plt.show()\n",
    "    current_x=0\n",
    "    current_y=0\n",
    "    next_x=28\n",
    "    next_y=28\n",
    "    coords=[current_x,current_y,next_x,next_y]\n",
    "    count=30\n",
    "    i=0\n",
    "    pbar = tqdm(total=5)\n",
    "    while i<=30 and next_y < image.shape[1]:\n",
    "        while next_x < image.shape[0]:\n",
    "            print(hawk)\n",
    "            cropped_image = image\n",
    "            #cropped_image.save(saved_location)\n",
    "            images.append(cropped_image)\n",
    "            coords=[current_x+28,current_y,next_x+28,next_y]\n",
    "            i+=1\n",
    "        current_x,current_y,next_x,next_y=0\n",
    "        coords=[current_x,current_y,next_x+28,next_y+28]\n",
    "        pbar.update(1)\n",
    "    \n",
    "    pbar.close()\n",
    "    cropped_image.show()\n",
    "    print(\"Done Cropping\")\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_model():\n",
    "\n",
    "    model=tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256,use_bias=True,input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.ReLU())\n",
    "\n",
    "    model.add(layers.Reshape((7,7,256)))\n",
    "    assert model.output_shape==(None,7,7,256)\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128,(5,5),strides=(1,1),padding='same',use_bias=True))\n",
    "    assert model.output_shape==(None,7,7,128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.ReLU())\n",
    "    \n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(64,(5,5),strides=(2,2),padding='same',use_bias=True))\n",
    "    assert model.output_shape==(None,14,14,64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.ReLU())\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(1,(5,5),strides=(2,2),padding='same',use_bias=True,activation='sigmoid'))\n",
    "    assert model.output_shape==(None,28,28,1)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xb3ad1f240>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator=generator_model()\n",
    "\n",
    "noise=tf.random.normal([1, 100])\n",
    "generated_image=generator(noise,training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0],cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_model():\n",
    "    model=tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64,(5,5),strides=(2,2),padding=\"same\",input_shape=[28,28,1]))\n",
    "    model.add(layers.ReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Conv2D(128,(5,5),strides=(2,2),padding='same'))\n",
    "    model.add(layers.ReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.06738296]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "discriminator=discriminator_model()\n",
    "decision=discriminator(generated_image)\n",
    "print(decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Losses and Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras helper function to compute cross entropy loss\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,discriminator_optimizer=discriminator_optimizer,generator=generator,discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# We will reuse this seed overtime (so it's easier)\n",
    "# to visualize progress in the animated GIF)\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "    print(\"in train_step\")\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "      generated_images = generator(noise, training=True)\n",
    "\n",
    "      real_output = discriminator(images, training=True)\n",
    "      fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "      gen_loss = generator_loss(fake_output)\n",
    "      disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    print(\"Epoch \"+epoch)\n",
    "    for image_batch in dataset:\n",
    "      train_step(image_batch)\n",
    "\n",
    "    # Produce images for the GIF as we go\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator,\n",
    "                             epoch + 1,\n",
    "                             seed)\n",
    "\n",
    "    # Save the model every 15 epochs\n",
    "    if (epoch + 1) % 15 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "  # Generate after the final epoch\n",
    "  display.clear_output(wait=True)\n",
    "  generate_and_save_images(generator,epochs,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  # Notice `training` is set to False.\n",
    "  # This is so all layers run in inference mode (batchnorm).\n",
    "  predictions = model(test_input, training=False)\n",
    "\n",
    "  fig = plt.figure(figsize=(4,4))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "      plt.subplot(4, 4, i+1)\n",
    "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "      plt.axis('off')\n",
    "\n",
    "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(img,time):\n",
    "    os.chdir(\"/Users/viggy/Documents/GitHub/AI-Music-Generator/ViolinMIDI/bwv1001/vs1-ada\")\n",
    "    every_second=image_slicer.slice(img, time)\n",
    "    return every_second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_1():\n",
    "    ala_path=\"/Users/viggy/Documents/GitHub/AI-Music-Generator/ViolinMIDI/bwv1001/vs1-ada\"\n",
    "    os.chdir(\"/Users/viggy/Documents/GitHub/AI-Music-Generator/ViolinMIDI/bwv1001/vs1-ada\")\n",
    "    png_data = numpy.empty\n",
    "    for filename in glob.glob(\"*.png\"):\n",
    "        png_data.append(np.array(Image.open(ala_path+\"/\"+filename)))\n",
    "    return png_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-cc01fddc35bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mala_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/Users/viggy/Documents/GitHub/AI-Music-Generator/ViolinMIDI/bwv1001/vs1-ada\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mala_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"reshaped\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#images.append(image_resized)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Path' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from scipy import ndimage, misc\n",
    "filepath=\"/Users/viggy/Documents/GitHub/AI-Music-Generator/ViolinMIDI/bwv1001/vs1-1ada.png\"\n",
    "#data=plt.imread(filepath)\n",
    "#data.shape\n",
    "#mage_resized = misc.imresize(image, (64, 64))\n",
    "#data = data.reshape(28, 28, 1).astype('float32')\n",
    "#data = (data - 127.5) / 127.5 # Normalize the images to [-1, 1]\n",
    "images = []\n",
    "\n",
    "ala_path=\"/Users/viggy/Documents/GitHub/AI-Music-Generator/ViolinMIDI/bwv1001/vs1-ada\"\n",
    "data_dir=Path(ala_path)\n",
    "print(\"reshaped\")\n",
    "#images.append(image_resized)\n",
    "#%%time\n",
    "im = plt.imread(filepath)\n",
    "print(im.shape)\n",
    "#uploaded=tf.image.decode_png(Image.open(filepath))\n",
    "#crop(im)\n",
    "#import cv2\n",
    "#colors=[]\n",
    "#colors=cv2.split(im)\n",
    "#split((filepath),224)\n",
    "#print(every_second)\n",
    "#uploaded = every_second.resize(every_second.shape[0], 28, 28, 3).astype('float32')\n",
    "\n",
    "dataset1=dataset_1()\n",
    "#dataset1=np.array(dataset1)\n",
    "print(dataset1[0].shape)\n",
    "#print(dataset1)\n",
    "uploaded = dataset1.reshape(dataset1.shape[0], 283, 283, 3).astype('float32')\n",
    "#uploaded = (uploaded - 127.5) / 127.5 # Normalize the images to [-1, 1]\n",
    "train(uploaded, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a single image using the epoch number\n",
    "def display_image(epoch_no):\n",
    "  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'image_at_epoch_0050.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-151-7d0477526f8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdisplay_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-150-2f3d8de0ec11>\u001b[0m in \u001b[0;36mdisplay_image\u001b[0;34m(epoch_no)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Display a single image using the epoch number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdisplay_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_no\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'image_at_epoch_{:04d}.png'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_no\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2634\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2635\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'image_at_epoch_0050.png'"
     ]
    }
   ],
   "source": [
    "display_image(EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim_file = 'dcgan.gif'\n",
    "\n",
    "with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "  filenames = glob.glob('image*.png')\n",
    "  filenames = sorted(filenames)\n",
    "  last = -1\n",
    "  for i,filename in enumerate(filenames):\n",
    "    frame = 2*(i**0.5)\n",
    "    if round(frame) > round(last):\n",
    "      last = frame\n",
    "    else:\n",
    "      continue\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)\n",
    "  image = imageio.imread(filename)\n",
    "  writer.append_data(image)\n",
    "\n",
    "import IPython\n",
    "if IPython.version_info > (6,2,0,''):\n",
    "  display.Image(filename=anim_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import math\n",
    "from PIL import Image\n",
    "from scipy.io.wavfile import read, write\n",
    "\n",
    "# read in the PNG file\n",
    "img = Image.open(\"/Users/viggy/Documents/GitHub/AI-Music-Generator/ViolinMIDI/bwv1001/vs1-1ada.png\")\n",
    "\n",
    "# look for the end indicator pixel and trim accordingly\n",
    "png_data = list(img.getdata())\n",
    "for i in range(len(png_data)):\n",
    "    if png_data[i] == [255, 255, 255]: # look for end pixel\n",
    "        png_data = png_data[:i]\n",
    "        break\n",
    "\n",
    "# convert data into WAV format\n",
    "wav_data = []\n",
    "for i in range(0, len(png_data), 2):\n",
    "    # read the first integer from 2x 8 bit integers in the first pixel,\n",
    "    # and the second from 2x 8 bit integers in the second pixel\n",
    "    wav_data.append([(png_data[i][0] << 8) + png_data[i][1], \n",
    "                     (png_data[i+1][0] << 8) + png_data[i+1][1]]) \n",
    "\n",
    "# output the WAV audio\n",
    "write('output.wav', 44100, numpy.asarray(wav_data, dtype=numpy.int16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
