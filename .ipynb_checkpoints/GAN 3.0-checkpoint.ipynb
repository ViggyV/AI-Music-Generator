{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN 3.0\n",
    "Through my research, I was able to decided to use a GAN to create music. I would first convert .wav files to pngs and use that throughout my GAN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The import statement above is used for some prints and special uses from tensorflow beta 2.0. Below of the required import statements to run and use the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-ae11338c1e1e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;31m#finds pathnames\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimageio\u001b[0m\u001b[1;31m#handles image input and output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;31m#data visulization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;31m#obivous array and math uses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import glob#finds pathnames\n",
    "import imageio#handles image input and output\n",
    "import matplotlib.pyplot as plt#data visulization\n",
    "import numpy as np#obivous array and math uses\n",
    "import os#helps uses files across different os\n",
    "import PIL#pictures\n",
    "import numpy\n",
    "import math\n",
    "from PIL import Image\n",
    "from scipy.io.wavfile import read, write\n",
    "from tensorflow.keras import layers#layers in the neural nets\n",
    "import time#to figure out timings\n",
    "\n",
    "from IPython import display#will show the resulting converted pngs\n",
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputting .wav files and Converting them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out\n",
      "vs1-2fug.wav\n",
      "work\n",
      "after png\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-46317ff57bf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# split all 16-bit integers in WAV file to 2x 8 bit integers;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# 1 16 bit int per pixel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0md_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>>\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0xff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0xff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0md_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>>\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0xff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0xff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mpng_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "os.chdir(\"/Users/viggy/Documents/GitHub/AI-Music-Generator/ViolinMIDI/bwv1001\")\n",
    "os.chdir(\"C:\\Users\\vigne\\Documents\\GitHub\\AI-Music-Generator\\ViolinMIDI\\bmv1001\")\n",
    "# read the WAV data\n",
    "wavs_in = []\n",
    "png_data = []\n",
    "song=0\n",
    "print(\"out\")\n",
    "\n",
    "for filename in glob.glob(\"*.wav\"):\n",
    "    print(filename)\n",
    "    print(\"work\")\n",
    "    wavs_in.append(read(filename))\n",
    "    wav_data = list(wavs_in[song][1])\n",
    "    #print(list(wavs_in[song]))\n",
    "    png_data = []\n",
    "    print(\"after png\")\n",
    "    for d in wav_data:\n",
    "        # split all 16-bit integers in WAV file to 2x 8 bit integers;\n",
    "        # 1 16 bit int per pixel\n",
    "        d_1 = (((d[0] >> 8) & 0xff), d[0] & 0xff, 0)\n",
    "        d_2 = (((d[1] >> 8) & 0xff), d[1] & 0xff, 0)\n",
    "        png_data.append(d_1)\n",
    "        png_data.append(d_2)\n",
    "    print(\"append\")\n",
    "    # ending indicator pixel uses the green channel\n",
    "    # (green channel set to 0 for all data pixels)\n",
    "    png_data += [(255, 255, 255)]\n",
    "    # find a roughly square size of output image\n",
    "    n = len(png_data)\n",
    "    x = math.floor(math.sqrt(n))\n",
    "    y = x + math.ceil((n - x ** 2) / x)\n",
    "\n",
    "    # output the PNG image\n",
    "    img = PIL.Image.new('RGB', (int(x), int(y)), color = 'white')\n",
    "    img.putdata(png_data)\n",
    "    img.save(filename.replace(\".wav\",\".png\"))\n",
    "    song+=1\n",
    "print(\"fin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_model():\n",
    "\n",
    "    model=tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256,use_bias=True,input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.ReLU())\n",
    "\n",
    "    model.add(layers.Reshape((7,7,256)))\n",
    "    assert model.output_shape==(None,7,7,256)\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128,(5,5),strides=(1,1),padding='same',use_bias=True))\n",
    "    assert model.output_shape==(None,7,7,128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.ReLU())\n",
    "    \n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(64,(5,5),strides=(2,2),padding='same',use_bias=True))\n",
    "    assert model.output_shape==(None,14,14,64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.ReLU())\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(1,(5,5),strides=(2,2),padding='same',use_bias=True,activation='sigmoid'))\n",
    "    assert model.output_shape==(None,28,28,1)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xb5ae5da20>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator=generator_model()\n",
    "\n",
    "noise=tf.random.normal([1, 100])\n",
    "generated_image=generator(noise,training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0],cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_model():\n",
    "    model=tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64,(5,5),strides=(2,2),padding=\"same\",input_shape=[28,28,1]))\n",
    "    model.add(layers.ReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Conv2D(128,(5,5),strides=(2,2),padding='same'))\n",
    "    model.add(layers.ReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.02759453]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "discriminator=discriminator_model()\n",
    "decision=discriminator(generated_image)\n",
    "print(decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Losses and Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras helper function to compute cross entropy loss\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,discriminator_optimizer=discriminator_optimizer,generator=generator,discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# We will reuse this seed overtime (so it's easier)\n",
    "# to visualize progress in the animated GIF)\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "      generated_images = generator(noise, training=True)\n",
    "\n",
    "      real_output = discriminator(images, training=True)\n",
    "      fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "      gen_loss = generator_loss(fake_output)\n",
    "      disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "\n",
    "    for image_batch in dataset:\n",
    "      train_step(image_batch)\n",
    "\n",
    "    # Produce images for the GIF as we go\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator,\n",
    "                             epoch + 1,\n",
    "                             seed)\n",
    "\n",
    "    # Save the model every 15 epochs\n",
    "    if (epoch + 1) % 15 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "  # Generate after the final epoch\n",
    "  display.clear_output(wait=True)\n",
    "  generate_and_save_images(generator,epochs,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  # Notice `training` is set to False.\n",
    "  # This is so all layers run in inference mode (batchnorm).\n",
    "  predictions = model(test_input, training=False)\n",
    "\n",
    "  fig = plt.figure(figsize=(4,4))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "      plt.subplot(4, 4, i+1)\n",
    "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "      plt.axis('off')\n",
    "\n",
    "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/viggy/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
      "Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'resize'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'resize'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from scipy import ndimage, misc\n",
    "filepath=\"/Users/viggy/Documents/GitHub/AI-Music-Generator/ViolinMIDI/bwv1001/vs1-1ada.png\"\n",
    "data=plt.imread(filepath)\n",
    "data.shape\n",
    "#mage_resized = misc.imresize(image, (64, 64))\n",
    "#data = data.reshape(28, 28, 1).astype('float32')\n",
    "#data = (data - 127.5) / 127.5 # Normalize the images to [-1, 1]\n",
    "images = []\n",
    "image = plt.imread(filepath)\n",
    "image_resized = misc.imresize(image, (28, 28))\n",
    "image_resized=np.array(Image.fromarray().resize(28,28))\n",
    "\n",
    "images.append(image_resized)\n",
    "train(images, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
