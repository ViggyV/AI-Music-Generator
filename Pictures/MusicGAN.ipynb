{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import datetime #to log times for each step\n",
    "import matplotlib.pyplot as plt #showing the results through \n",
    "import numpy as np#matrix math\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-beta0'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "musicFile=\"/Users/viggy/Documents/GitHub/AI-Music-Generator/ViolinMIDI\"\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "filenames=glob.glob(\"*.mid\")\n",
    "test_file=\"/Users/viggy/Documents/GitHub/AI-Music-Generator/ViolinMIDI/BachChaconne.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pygame\n",
    "def play_music(music_file):\n",
    "    clock=pygame.time.Clock()\n",
    "    try:\n",
    "        pygame.mixer.music.load(music_file)\n",
    "    except pygame.error:\n",
    "            print (\"Not found\")\n",
    "            return\n",
    "    pygame.mixer.music.get_busy()\n",
    "    pygame.mixer.init(44100,-16,2,1024)\n",
    "    pygame.mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(input_music, passes=False):\n",
    "    if(passes):\n",
    "        tf.get_variables_scope().reuse_variables()\n",
    "    #First Convoultion Block\n",
    "    #matrix layer one\n",
    "    layer_w1=tf.get_variable('layer_w1',[5,5,1,32],initializer=truncated_normal_initializer(stddev=0.02))\n",
    "    #creates the bias for this layer to improve convergence\n",
    "    layer_b1=tf.get_variable('layer_b1',[32],initializer=tf.constant_initializer(0))\n",
    "    \n",
    "    layer1=tf.nn.conv2d(input_music,filter=layer_w1,strides=[1,1,1,1], padding='SAME')\n",
    "    layer1=layer1+layer_b1\n",
    "    layer1=tf.nn.relu(layer1)\n",
    "    \n",
    "    #or max pooling\n",
    "    layer1=tf.nn.avg_pool(layer1,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "    \n",
    "    #layer2\n",
    "    layer_w2=tf.get_variable('layer_w2',[5,5,32,64],initializer=truncated_normal_initializer(stddev=0.02))\n",
    "    layer_b2=tf.get_variable('layer_2',[64],initializer=tf.constant_initializer(0))\n",
    "    \n",
    "    layer2=tf.nn.conv2d(layer1,filter=layer_w2,strides=[1,1,1,1], padding='SAME')\n",
    "    layer2=layer2+layer_b2\n",
    "    layer2=tf.nn.relu(layer2)\n",
    "    \n",
    "    #or max pooling\n",
    "    layer2=tf.nn.avg_pool(layer2,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "                          \n",
    "    layer_w3=tf.get_variable('layer_w3',[7*7*64,1024],initializer=truncated_normal_initializer(stddev=0.02))\n",
    "    layer_b3=tf.get_variable('layer_b3',[1024],initializer=tf.constant_initializer(0))\n",
    "    \n",
    "    layer3=tf.reshape(layer2,[-1,7*7*64])\n",
    "    layer3=tf.matmul(layer3,layer_w3)                     \n",
    "    layer3=layer3+layer_b3\n",
    "    layer3=tf.nn.relu(layer3)\n",
    "    \n",
    "    layer_w4=tf.get_variable('layer_w4',[1024,1],initializer=truncated_normal_initializer(stddev=0.02))\n",
    "    layer_b4=tf.get_variable('layer_b4',[1],initializer=tf.constant_initializer(0)) \n",
    "                          \n",
    "    layer4=tf.matmul(layer3,layer_w4)+layer_b4\n",
    "                          \n",
    "    return layer4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "    model=tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256),use_bias=True,input_shape=(100,))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Reshape(7,7,256))\n",
    "    assert model.output_shape == (None, 7, 7, 256)\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes 2 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-938fbe30df76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgenerated_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-adfe86f22ec6>\u001b[0m in \u001b[0;36mgenerator\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLeakyReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_shape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() takes 2 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "generator = generator()\n",
    "\n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
